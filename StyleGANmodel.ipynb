{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ILrvLXPePk4w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from math import log2\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "factors = [1, 1, 1, 1, 1/2, 1/4, 1/16, 1/32]"
      ],
      "metadata": {
        "id": "6GjlzJtnPu45"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PixelNorm(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PixelNorm, self).__init__()\n",
        "    self.epsilon = 1e-8\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.unsqueeze(1)\n",
        "    return x / torch.sqrt((torch.mean(x**2, dim = 1, keepdim = True)) + self.epsilon)\n"
      ],
      "metadata": {
        "id": "ZayG3j8XQz7t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WSLinear(nn.Module):\n",
        "  def __init__(self, in_features, out_features, gains = 2):\n",
        "    super(WSLinear, self).__init__()\n",
        "    self.linear = nn.Linear(in_features, out_features)\n",
        "    self.scale = (gains/ in_features)**(0.5)\n",
        "    self.bias = self.linear.bias\n",
        "    self.linear.bias = None\n",
        "    nn.init.normal_(self.linear.weight)\n",
        "    nn.init.zeros_(self.bias)\n",
        "  def forward(self, x):\n",
        "    return self.linear(x * self.scale) + self.bias"
      ],
      "metadata": {
        "id": "nsRBe-NJRqnY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WSConv2d(nn.Module):\n",
        "  def __init__(self, in_features, out_features, kernel_size = 3, stride = 1, padding = 1, gains = 2):\n",
        "    super(WSConv2d, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_features, out_features, kernel_size, stride, padding)\n",
        "    self.scale = (gains / (kernel_size)**2 * in_features)**(0.5)\n",
        "    self.bias = self.conv.bias\n",
        "    self.conv.bias = None\n",
        "    nn.init.normal_(self.conv.weight)\n",
        "    nn.init.zeros_(self.bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x * self.scale) + self.bias"
      ],
      "metadata": {
        "id": "NQI15jMITmhs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StyleScale(torch.nn.Module):\n",
        "    def __init__(self, num_channels, num_styles):\n",
        "        super().__init__()\n",
        "        self.scale = torch.zeros((num_channels, num_styles, 1, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.scale"
      ],
      "metadata": {
        "id": "rd8Svz9SLNj7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaIN(nn.Module):\n",
        "    def __init__(self, in_channels, style_dim):\n",
        "        super().__init__()\n",
        "        self.InstanceNorm = nn.InstanceNorm2d(in_channels)\n",
        "        self.scale = nn.Parameter(torch.ones(1, in_channels, 1, 1))\n",
        "        self.bias = nn.Parameter(torch.zeros(1, in_channels, 1, 1))\n",
        "        self.style_scale = StyleScale(style_dim, in_channels)\n",
        "        self.style_bias = StyleScale(style_dim, in_channels)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        self.scale = self.scale.to(x.device)\n",
        "        self.bias = self.bias.to(x.device)\n",
        "\n",
        "        x = self.InstanceNorm(x)\n",
        "        style_scale = self.style_scale(w).unsqueeze(3)\n",
        "        style_bias = self.style_bias(w).unsqueeze(3)\n",
        "        return style_scale * x + style_bias"
      ],
      "metadata": {
        "id": "3fr9IfPYTnqh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MappingNetwork(nn.Module):\n",
        "  def __init__(self, z_dim, w_dim):\n",
        "    super().__init__()\n",
        "    self.mapping = nn.Sequential(\n",
        "        PixelNorm(),\n",
        "        WSLinear(z_dim, w_dim),\n",
        "        nn.ReLU(),\n",
        "        WSLinear(w_dim, w_dim),\n",
        "        nn.ReLU(),\n",
        "        WSLinear(w_dim, w_dim),\n",
        "        nn.ReLU(),\n",
        "        WSLinear(w_dim, w_dim),\n",
        "        nn.ReLU(),\n",
        "        WSLinear(w_dim, w_dim),\n",
        "        nn.ReLU(),\n",
        "        WSLinear(w_dim, w_dim),\n",
        "        nn.ReLU(),\n",
        "        WSLinear(w_dim, w_dim),\n",
        "        nn.ReLU(),\n",
        "        WSLinear(w_dim, w_dim)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.mapping(x)"
      ],
      "metadata": {
        "id": "xJpqhg7aTntc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InjectNoise(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.zeros(1, channels, 1, 1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    noise = torch.randn((x.shape[0], 1, x.shape[2], x.shape[3]), device=x.device)\n",
        "    return x + self.weight * noise"
      ],
      "metadata": {
        "id": "9OegRO4MTnwI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.conv1 = WSConv2d(in_channels, out_channels)\n",
        "    self.conv2 = WSConv2d(out_channels, out_channels)\n",
        "    self.leaky = nn.LeakyReLU(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.leaky(self.conv1(x))\n",
        "    x = self.leaky(self.conv2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "nl3Nt7gxTnyt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GenBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, w_dim):\n",
        "        super(GenBlock, self).__init__()\n",
        "        self.conv1 = WSConv2d(in_channels, out_channels)\n",
        "        self.conv2 = WSConv2d(out_channels, out_channels)\n",
        "        self.leaky = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.inject_noise1 = InjectNoise(out_channels)\n",
        "        self.inject_noise2 = InjectNoise(out_channels)\n",
        "        self.adain1 = AdaIN(out_channels, w_dim)\n",
        "        self.adain2 = AdaIN(out_channels, w_dim)\n",
        "\n",
        "    def forward(self, x, w):\n",
        "        x = self.adain1(self.leaky(self.inject_noise1(self.conv1(x))), w)\n",
        "        x = self.adain2(self.leaky(self.inject_noise2(self.conv2(x))), w)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ab6YN8vMTn1i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim, w_dim, in_channels, img_channels = 3):\n",
        "    super(Generator, self).__init__()\n",
        "    self.starting_constant = nn.Parameter(torch.ones((1, in_channels, 4, 4)))\n",
        "    self.map = MappingNetwork(z_dim, w_dim)\n",
        "    self.initial_adain1 = AdaIN(in_channels, z_dim)\n",
        "    self.initial_adain2 = AdaIN(in_channels, w_dim)\n",
        "    self.initial_noise1 = InjectNoise(in_channels)\n",
        "    self.initial_noise2 = InjectNoise(in_channels)\n",
        "    self.initial_conv = nn.Conv2d(in_channels, in_channels, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.leaky = nn.LeakyReLU(0.2, inplace = True)\n",
        "    self.initial_rgb = WSConv2d(in_channels, img_channels, kernel_size = 1, stride = 1, padding = 0)\n",
        "    self.prog_blocks, self.rgb_layers = (nn.ModuleList([]), nn.ModuleList([self.initial_rgb]))\n",
        "    for i in range(len(factors) - 1):\n",
        "      conv_in_c = int(in_channels * factors[i])\n",
        "      conv_out_c = int(in_channels * factors[i + 1])\n",
        "      self.prog_blocks.append(GenBlock(conv_in_c, conv_out_c, w_dim))\n",
        "      self.rgb_layers.append(WSConv2d(conv_out_c, img_channels, kernel_size = 1, stride = 1, padding = 0))\n",
        "\n",
        "  def fade_in(self, alpha, upscaled, generated):\n",
        "    return torch.tanh(alpha * generated + (1 - alpha) * upscaled)\n",
        "\n",
        "  def forward(self, noise, alpha, steps):\n",
        "    w = self.map(noise)\n",
        "    x = self.initial_adain1(self.initial_noise1(self.starting_constant), w)\n",
        "    x = self.initial_conv(x)\n",
        "    out = self.initial_adain2(self.leaky(self.initial_noise2(x)), w)\n",
        "    if steps == 0:\n",
        "      return self.initial_rgb(x)\n",
        "\n",
        "    for step in range(steps):\n",
        "      upscaled = F.interpolate(out, scale_factor = 2, mode = \"bilinear\")\n",
        "      out = self.prog_blocks[step](upscaled, w)\n",
        "      final_upscaled = self.rgb_layers[steps - 1](upscaled)\n",
        "      final_out = self.rgb_layers[steps](out)\n",
        "      return self.fade_in(alpha, final_upscaled, final_out)"
      ],
      "metadata": {
        "id": "2RwtfCbOTn4Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels, img_channels = 3):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.prog_blocks, self.rgb_layers = nn.ModuleList([]), nn.ModuleList([])\n",
        "    self.leaky = nn.LeakyReLU(0.2)\n",
        "    for i in range(len(factors) - 1, 0, -1):\n",
        "      conv_in = int(in_channels * factors[i])\n",
        "      conv_out = int(in_channels * factors[i - 1])\n",
        "      self.prog_blocks.append(ConvBlock(conv_in, conv_out))\n",
        "      self.rgb_layers.append(WSConv2d(img_channels, conv_in, kernel_size = 1, stride = 1, padding = 0))\n",
        "    self.initial_rgb = WSConv2d(img_channels, in_channels, kernel_size = 1, stride = 1, padding = 0)\n",
        "    self.avg_pool = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "    self.final_block = nn.Sequential(WSConv2d(in_channels + 1, in_channels, kernel_size = 3, padding = 1),\n",
        "                                     nn.LeakyReLU(0.2),\n",
        "                                     WSConv2d(in_channels, in_channels, kernel_size = 4, padding = 0, stride = 1),\n",
        "                                     nn.LeakyReLU(0.2),\n",
        "                                     WSConv2d(in_channels, 1, kernel_size = 1, padding = 0, stride = 1))\n",
        "  def fade_in(self, alpha, downscaled, out):\n",
        "    return alpha * out + (1 - alpha) * downscaled\n",
        "  def minibatch_std(self, x):\n",
        "    batch_statistics = (torch.std(x, dim = 0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3]))\n",
        "    return torch.cat([x, batch_statistics], dim = 1)\n",
        "  def forward(self, x, alpha, steps):\n",
        "    cur_step = len(self.prog_blocks) - steps\n",
        "    out = self.leaky(self.rgb_layers[cur_step](x))\n",
        "\n",
        "    if steps == 0:\n",
        "      out = self.minibatch_std(out)\n",
        "      return self.final_block(out).view(out.shape[0], -1)\n",
        "\n",
        "    downscaled = self.leaky(self.rgb_layers[cur_step + 1](self.avg_pool(x)))\n",
        "    out = self.avg_pool(self.prog_blocks[cur_step](out))\n",
        "\n",
        "    for step in range(cur_step + 1, len(self.prog_blocks)):\n",
        "      out = self.prog_blocks[step](out)\n",
        "      out = self.avg_pool(out)\n",
        "\n",
        "    out = self.minibatch_std(out)\n",
        "    return self.final_block(out).view(out.shape[0], -1)"
      ],
      "metadata": {
        "id": "RMEgSpf2Tn6p"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z_DIM = 512\n",
        "W_DIM = 512\n",
        "IN_CHANNELS = 512\n",
        "gen = Generator(Z_DIM, W_DIM, IN_CHANNELS, img_channels=3)\n",
        "disc = Discriminator(IN_CHANNELS, img_channels=3)\n",
        "tot = 0\n",
        "for param in gen.parameters():\n",
        "  tot += param.numel()\n",
        "print(tot)\n",
        "for img_size in [4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
        "  num_steps = int(log2(img_size / 4))\n",
        "  x = torch.randn((2, Z_DIM))\n",
        "  z = gen(x, alpha = 0.5, steps = num_steps)\n",
        "  assert z.shape == (2, 3, img_size, img_size)\n",
        "  out = disc(z, alpha=0.5, steps=num_steps)\n",
        "  assert out.shape == (2, 1)\n",
        "  print(f\"Success! At img size: {img_size}\")"
      ],
      "metadata": {
        "id": "0yTk6DvjToAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8656904-e59e-4fe7-c66c-0b27495ad085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20916136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNXdQPpIToCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1P-mjAztAXI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}